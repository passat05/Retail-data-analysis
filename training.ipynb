{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('https://raw.githubusercontent.com/passat05/Retail-data-analysis/272b60543e7f4a5197a0f463cf7076917df69293/Features%20data%20set.csv')\n",
    "stores = pd.read_csv('https://raw.githubusercontent.com/passat05/Retail-data-analysis/272b60543e7f4a5197a0f463cf7076917df69293/stores%20data-set.csv')\n",
    "sales = pd.read_csv('https://raw.githubusercontent.com/passat05/Retail-data-analysis/272b60543e7f4a5197a0f463cf7076917df69293/sales%20data-set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.merge(sales, features.loc[:, features. columns != 'IsHoliday'],how = 'left', on = ['Store','Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.merge(summary, stores, how = 'left', on = ['Store'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary['Weekly_Sales'] = np.where(summary['Weekly_Sales'] < 0, 0, summary['Weekly_Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary['Date'] = pd.to_datetime(summary['Date'], format='%d/%m/%Y')\n",
    "summary['WeekOfYear'] = summary.Date.dt.isocalendar().week\n",
    "summary['Year'] = summary.Date.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "occasion = {\n",
    "    '10-02': 'Super Bowl',\n",
    "    '11-02': 'Super Bowl',\n",
    "    '12-02': 'Super Bowl',\n",
    "    # '13-02': 'Official Super Bowl'\n",
    "    # '04-09': 'Official Labor Day',\n",
    "    '07-09': 'Labor Day',\n",
    "    '09-09': 'Labor Day',\n",
    "    '10-09': 'Labor Day',\n",
    "    '17-02': \"Presidents' Day\",\n",
    "    '18-02': \"Presidents' Day\",\n",
    "    '19-02': \"Presidents' Day\",\n",
    "    '02-04': \"Easter Day\",\n",
    "    '01-04': \"Easter Day\",\n",
    "    '30-03': \"Easter Day\",\n",
    "    '25-11': 'Thanksgiving',\n",
    "    '26-11': 'Thanksgiving',\n",
    "    '16-12': 'Before Christmas 1W',\n",
    "    '17-12': 'Before Christmas 1W',\n",
    "    '23-12': 'Christmas',\n",
    "    '24-12': 'Christmas'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary['Occasion'] = summary['Date'].dt.strftime(\"%d-%m\").map(occasion)\n",
    "summary['Occasion'].fillna('Normal', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary['IsHoliday'] = summary['IsHoliday'].replace(True, 1).replace(False, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.columns = summary.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.sort_values(by=['date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics_cols = [i for i in summary.select_dtypes(include='number').columns.to_list() if i not in 'weekly_sales']\n",
    "categorical_cols = ['type','occasion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_df = pd.get_dummies(summary[categorical_cols],prefix='_',prefix_sep='',dtype=float)\n",
    "one_hot_cols = one_hot_df.columns\n",
    "df = pd.merge(summary[numerics_cols + ['weekly_sales']], one_hot_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[:int(.7*len(df))].reset_index(drop=True)\n",
    "df_val = df[int(.7*len(df)):int(.85*len(df))].reset_index(drop=True)\n",
    "df_test = df[int(.85*len(df)):].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.log1p(df_train.weekly_sales)\n",
    "y_val = np.log1p(df_val.weekly_sales)\n",
    "y_test = np.log1p(df_test.weekly_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train['weekly_sales']\n",
    "del df_val['weekly_sales']\n",
    "del df_test['weekly_sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler().fit(df_train[numerics_cols])\n",
    "for x in [df_train,df_val,df_test]:\n",
    "    x[numerics_cols] = scaler.transform(x[numerics_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train\n",
    "X_val = df_val\n",
    "X_test = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=50, random_state=1)\n",
    "model = rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"scaler_forecast_model.bin\", \"wb\") as f_out:\n",
    "    pickle.dump((scaler, model), f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"scaler_forecast_model.bin\", \"rb\") as f_in:\n",
    "#     scaler, _ = pickle.load(f_in)\n",
    "#     # _, model = pickle.load(f_in)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
